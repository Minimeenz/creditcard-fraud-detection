{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4578360",
   "metadata": {},
   "source": [
    " Credit Card Fraud Detection using Supervised Learning\n",
    "\n",
    "This notebook demonstrates a complete supervised-learning workflow for detecting fraudulent credit-card transactions. It includes problem description, EDA, preprocessing, modeling, evaluation, and discussion.\n",
    "\n",
    "Dataset: [Kaggle Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)\n",
    "\n",
    "Target: `Class` → 1 = Fraud, 0 = Legitimate\n",
    "\n",
    "Challenge: Highly imbalanced dataset; precision/recall and ROC-AUC are more informative than accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0095f2c",
   "metadata": {},
   "source": [
    "1. Imports & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310fff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score, \n",
    "                             roc_curve, ConfusionMatrixDisplay)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the dataset (place creditcard.csv in the same folder or update the path)\n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9219f83c",
   "metadata": {},
   "source": [
    "2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7799208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Missing values\n",
    "print(\"Total missing values:\", df.isnull().sum().sum())\n",
    "\n",
    "# Class balance\n",
    "sns.countplot(x='Class', data=df, palette='Set2')\n",
    "plt.title(\"Class Distribution – Legit (0) vs Fraud (1)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Class balance (proportion):\")\n",
    "print(df['Class'].value_counts(normalize=True))\n",
    "\n",
    "# Distributions for Amount & Time\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,5))\n",
    "sns.histplot(df['Amount'], bins=50, ax=ax[0], color='teal')\n",
    "sns.histplot(df['Time'],   bins=50, ax=ax[1], color='orange')\n",
    "ax[0].set_title(\"Transaction Amount Distribution\")\n",
    "ax[1].set_title(\"Transaction Time Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df.corr(), cmap='coolwarm', center=0)\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454e3661",
   "metadata": {},
   "source": [
    "3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde7a4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "# Scale 'Amount' and 'Time'\n",
    "scaler = StandardScaler()\n",
    "X[['Amount','Time']] = scaler.fit_transform(X[['Amount','Time']])\n",
    "\n",
    "# Stratified train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Fraud ratio in train:\", y_train.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cd2838",
   "metadata": {},
   "source": [
    "4. Modeling: Logistic Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b037548",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr = LogisticRegression(class_weight='balanced', max_iter=500, random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Results\")\n",
    "print(classification_report(y_test, y_pred_lr, digits=4))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, lr.predict_proba(X_test)[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e705f2f3",
   "metadata": {},
   "source": [
    "5. Modeling: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8520c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Results\")\n",
    "print(classification_report(y_test, y_pred_rf, digits=4))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, rf.predict_proba(X_test)[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5dbfc8",
   "metadata": {},
   "source": [
    "6. Results Visualization: Confusion Matrix & ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb90c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confusion Matrix\n",
    "ConfusionMatrixDisplay.from_estimator(rf, X_test, y_test, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix – Random Forest\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, rf.predict_proba(X_test)[:,1])\n",
    "roc_auc = roc_auc_score(y_test, rf.predict_proba(X_test)[:,1])\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC={roc_auc:.3f})\")\n",
    "plt.plot([0,1],[0,1],'--',color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve – Random Forest\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35822594",
   "metadata": {},
   "source": [
    "7. SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08b7fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Uncomment to use SMOTE (requires imblearn)\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# sm = SMOTE(random_state=42)\n",
    "# X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "# print(\"Before SMOTE fraud ratio:\", y_train.mean())\n",
    "# print(\"After SMOTE fraud ratio:\", y_res.mean())\n",
    "# rf_sm = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# rf_sm.fit(X_res, y_res)\n",
    "# y_pred_sm = rf_sm.predict(X_test)\n",
    "# print(\"Random Forest + SMOTE Results\")\n",
    "# print(classification_report(y_test, y_pred_sm, digits=4))\n",
    "# print(\"ROC-AUC:\", roc_auc_score(y_test, rf_sm.predict_proba(X_test)[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f3a1fc",
   "metadata": {},
   "source": [
    "Discussion & Conclusion: \n",
    "The dataset is extremely imbalanced; recall and ROC-AUC are critical\n",
    "Logistic Regression with class weighting provides a baseline\n",
    "Random Forest generally improves performance (precision/recall trade-off)\n",
    "SMOTE can further improve recall at the expense of precision\n",
    "Next Steps: GridSearchCV for RF hyperparameters; try anomaly detection methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
